<!DOCTYPE html>
<html lang="en">
<head>
        <title>Nonlinear Units</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css" />
        <link rel="stylesheet" href="./theme/css/main.css" />
</head>
<body>

    <div class="navigation pure-menu pure-menu-horizontal">
        <a href="./" class="pure-menu-heading  pure-menu-link">Slacy's Blog</a>
        <ul class="pure-menu-list">
            <li class="pure-menu-item"></li>

        </ul>
    </div>


<div class="page-container">
    <div class="entry-content">
        <div class="post-meta pure-g">
            <div class="pure-u">
                <a href="./category/tensorflow-from-the-ground-up.html"><img src="https://slacy.github.io/blog/images/tf_logo.png " class="post-avatar" alt="TensorFlow From The Ground Up"></a>
            </div>
<div class="pure-u-3-4 meta-data">
    <a href="./category/tensorflow-from-the-ground-up.html" class="category">TensorFlow From The Ground Up</a><br />

    <a class="author" href="./author/slacy.html">slacy</a>
    &mdash; <abbr title="2017-02-10T11:00:00-08:00">Fri 10 February 2017</abbr>
</div>        </div>
    </div>

    <div class="article-header-container">
        <div class="background-image-container">

            <div class="background-image-small">
                <div class="title-container">
                    <h1>Nonlinear Units</h1>
                </div>
            </div>
        </div>
    </div>

    <div class="entry-content">
        <p>This post part of my series <a href="./category/tensorflow-from-the-ground-up.html">TensorFlow From The Ground Up</a>.</p>
<p>In my previous post <a href="./learning-to-add.html">Learning to Add</a>, I showed how a Neural Network architecture can learn a simple linear function of two variables.  </p>
<p>In this post, we'll explore how to take our functions from linear to nonlinear.  Additionally, we'll work on going some <strong>regressions</strong> and see what happens when we try to learn nonlinear functions. </p>
<h2>Composing linear functions</h2>
<p>One of the key points of linear functions is that the composition of two linear functions is also a linear function.  The math behind this is fairly straightforward: </p>
<div class="math">$$\begin{array}{rl}
f(x) &amp; = wx+b \\
f(f(x)) &amp; = w_2(w_1x+b_1)+b_2 \\
&amp; = (w_2w_1)x+(w_2b_1+b_2) \\
\end{array}$$</div>
<p>As you can see, the composed form of <span class="math">\(f(f(x))\)</span> is also a linear function, just with <span class="math">\(w = w_2w_1\)</span> and <span class="math">\(b = w_2b_1+b_2\)</span></p>
<p>Or, to think of this differently:  Without any <strong>nonlinear elements</strong> in our neural network architecture, there's no reason to have any more than one node in the middle layer, because even a giant collection of linear functions still result in a single linear transformation.  </p>
<p>An exception to this is functions of multiple variables, like <span class="math">\(f(x,y) = \{a,b\}\)</span>  We can work the math backwards, but let it suffice to say that for functions of <span class="math">\(N\)</span> inputs and <span class="math">\(M\)</span> outputs, we need no more than <span class="math">\(\max(N,M)\)</span> linear 
nodes in the middle layer. </p>
<h2>How do we introduce nonlinearity?</h2>
<p>All we need to do is apply some elementwise nonlinear function to all the values in the middle layer of our network.  It ends up making our computation graph look like this: </p>
<div class="math">$$\begin{array}{rl}
middle\ layer &amp; = input \times W_{mid} + B_{mid} \\
middle\ nonlinear &amp; = f(middle\ layer) \\ 
output &amp; = (midle\ nonlinear) \times W_{out} + B_{out}
\end{array}$$</div>
<p>It's that easy, we just need to choose the right nonlinear function to insert there.  Thankfully, this has been heavily researched, and there are 3 very commonly used functions:</p>
<ul>
<li><strong>sigmoid</strong> : <code>tf.nn.sigmoid</code></li>
<li><strong>tanh</strong> : <code>tf.nn.tanh</code></li>
<li><strong>ReLu</strong>  : <code>tf.nn.relu</code></li>
</ul>
<p>The best way to get a grasp on these is to look at them visually, so here we go: </p>
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s1">&#39;svg&#39;</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span> 

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span> 
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="mi">0</span> 

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">relu</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ReLU&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="svg" src="./images/NonlinearUnits_files/NonlinearUnits_5_0.svg"></p>
<h2>Simple Example</h2>
<p>As an example of computation that requires nonlinear units, I'd like to propose that we implement a function like this: 
</p>
<div class="math">$$f(x) = \begin{cases}
    1.0, &amp; \text{if } \lfloor x \rfloor = 42 \\
    0,         &amp; \text{otherwise}
\end{cases}
$$</div>
<p>This function isn't easily expressed through any combination of linear operators.  Additionally, the fact that the output should be either 1.0 or 0.0 after training suggests that we should use the <strong>sigmoid</strong> function for activation of the neuron(s) in the network. </p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span> 
<span class="kn">import</span> <span class="nn">random</span>

<span class="n">t</span> <span class="o">=</span> <span class="mf">30.</span>
<span class="n">min_t</span> <span class="o">=</span> <span class="mf">25.</span>
<span class="n">max_t</span> <span class="o">=</span> <span class="mf">35.</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> 
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">t</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span> 
    <span class="k">return</span> <span class="mi">0</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>

<span class="n">num_hidden</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">i_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">expected_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">),</span> 
                <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">i_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">expected_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">),</span> 
                <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="n">mid</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i_w</span><span class="p">),</span> <span class="n">i_b</span><span class="p">))</span>
<span class="c1"># mid = tf.add(tf.matmul(i, i_w), i_b)</span>

<span class="n">o_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
    <span class="n">expected_shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
    <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="n">num_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">o_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
    <span class="n">expected_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
    <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="n">o_w</span><span class="p">),</span> <span class="n">o_b</span><span class="p">))</span>
<span class="c1"># output = tf.add(tf.matmul(mid, o_w), o_b)</span>

<span class="c1"># Our error function is computed as &quot;Mean Squared Difference&quot; between the computed output</span>
<span class="c1"># and the expected value. </span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">output</span> <span class="o">-</span> <span class="n">o</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">mean_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="c1"># Learning rate and optimizer similar to our previous examples. </span>
<span class="c1"># learning_rate = 0.0001</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span> 
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">(),</span> 
              <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()])</span>

    <span class="k">print</span> <span class="s2">&quot;TRAIN&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">train_iterations</span> <span class="o">=</span> <span class="mi">50000</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">train_iterations</span><span class="p">):</span>
        <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:[],</span> <span class="n">o</span><span class="p">:[]}</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">batch_size</span><span class="o">/</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">min_t</span><span class="p">,</span> <span class="n">max_t</span><span class="p">)</span>
            <span class="n">feed</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">v</span><span class="p">,])</span>
            <span class="n">feed</span><span class="p">[</span><span class="n">o</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">),])</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mean_loss</span><span class="p">,</span> <span class="n">output</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">5000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="s2">&quot;step =&quot;</span><span class="p">,</span><span class="n">step</span><span class="p">,</span><span class="s2">&quot; loss=&quot;</span><span class="p">,</span> <span class="n">l</span>

    <span class="k">print</span> <span class="s2">&quot;VALIDATE&quot;</span>
    <span class="n">validate_iterations</span> <span class="o">=</span> <span class="mi">15</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">validate_iterations</span><span class="p">):</span>
        <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:[],</span> <span class="n">o</span><span class="p">:[]}</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">min_t</span><span class="p">,</span> <span class="n">max_t</span><span class="p">)</span>
        <span class="n">feed</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">v</span><span class="p">,])</span>
        <span class="n">feed</span><span class="p">[</span><span class="n">o</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">),])</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mean_loss</span><span class="p">,</span> <span class="n">output</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
        <span class="k">print</span> <span class="s2">&quot;in = &quot;</span><span class="p">,</span> <span class="n">feed</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s2">&quot;output =&quot;</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="s2">&quot;expected = &quot;</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="s2">&quot; loss=&quot;</span><span class="p">,</span> <span class="n">l</span>


    <span class="k">print</span> <span class="s2">&quot;GRAPH&quot;</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">min_t</span><span class="p">,</span><span class="n">max_t</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">i</span><span class="p">:[[</span><span class="n">ix</span><span class="p">,]</span> <span class="k">for</span> <span class="n">ix</span> <span class="ow">in</span> <span class="n">tx</span><span class="p">],})</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learned&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">fx</span><span class="p">)</span> <span class="k">for</span> <span class="n">fx</span> <span class="ow">in</span> <span class="n">tx</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;f(x)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span>TRAIN
step = 0  loss= 1.83179e+06
step = 5000  loss= 0.156334
step = 10000  loss= 0.197727
step = 15000  loss= 0.145691
step = 20000  loss= 0.0489364
step = 25000  loss= 0.0920705
step = 30000  loss= 0.0996958
step = 35000  loss= 0.0495032
step = 40000  loss= 0.0642934
step = 45000  loss= 0.0641886
VALIDATE
in =  [[32.003762118671474]] output = [[ 0.76464736]] expected =  1  loss= 0.0553909
in =  [[32.36696377797531]] output = [[ 0.82751727]] expected =  1  loss= 0.0297503
in =  [[29.104202468396544]] output = [[ 0.24386668]] expected =  0  loss= 0.059471
in =  [[25.386498517093727]] output = [[ 0.]] expected =  0  loss= 0.0
in =  [[33.06359502062598]] output = [[ 0.94786686]] expected =  1  loss= 0.00271786
in =  [[25.46369592630006]] output = [[ 0.]] expected =  0  loss= 0.0
in =  [[34.76348901877117]] output = [[ 1.2494638]] expected =  1  loss= 0.0622322
in =  [[32.77071202248998]] output = [[ 0.88596189]] expected =  1  loss= 0.0130047
in =  [[33.86705852782782]] output = [[ 1.07837367]] expected =  1  loss= 0.00614243
in =  [[33.21695256720534]] output = [[ 0.95710593]] expected =  1  loss= 0.0018399
in =  [[25.06452496846031]] output = [[ 0.]] expected =  0  loss= 0.0
in =  [[26.761287670627226]] output = [[ 0.]] expected =  0  loss= 0.0
in =  [[31.26943022484645]] output = [[ 0.60015279]] expected =  1  loss= 0.159878
in =  [[34.61701252905589]] output = [[ 1.20263445]] expected =  1  loss= 0.0410607
in =  [[31.322623992257483]] output = [[ 0.61499643]] expected =  1  loss= 0.148228
GRAPH
</pre></div>


<p><img alt="svg" src="./images/NonlinearUnits_files/NonlinearUnits_7_1.svg"></p>
<h2>You should play with this code a little bit.</h2>
<p>Here's a collection of random ideas for how to play around with the code example above and gain some insights:</p>
<ul>
<li>Modify the "f()" function to try other linear combinations of x &amp; y.  Can it learn <span class="math">\(x-y\)</span>?  Can it learn <span class="math">\(0.5x + 0.75y - 0.33\)</span>? </li>
<li>Modify the size of the middle layer.  We use 2 middle layer nodes.  What if you use 200?  How does that impact learning rate?   </li>
<li>Modify the size of the middle layer, and have it try to learn something "Hard" like <span class="math">\(x\cdot y\)</span>. Did it work?  Do you have any thoughts about why or why not?</li>
</ul>
<div class="highlight"><pre><span></span>
</pre></div>


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div>

    <footer>
        <div class="tags">
            <a href="./tag/python.html">Python</a>
            <a href="./tag/tensorflow.html">TensorFlow</a>
            <a href="./tag/jupyter.html">Jupyter</a>
        </div>
        <div class="pure-g post-footer">
            <div class="pure-u-1 pure-u-md-1-2">
                <div class="pure-g poster-info">
                    <div class="pure-u">
                        <a href="./author/slacy.html"><img src="https://slacy.github.io/blog/images/ygg.png" alt=""></a>
                    </div>
                    <div class="pure-u-3-4">
                        <h3 class="author-name"><a href="./author/slacy.html">slacy</a></h3>
                        <p class="author-description">
                                              
                        </p>
                    </div>
                </div>
            </div>


            <div class="pure-u-1 pure-u-md-1-2">

                <div class="pure-g post-category-info">
                    <div class="pure-u">
                        <a href="./category/tensorflow-from-the-ground-up.html"><img src="https://slacy.github.io/blog/images/tf_logo.png" alt=""></a>
                    </div>
                    <div class="pure-u-3-4">
                        <h3 class="author-name"><a href="./category/tensorflow-from-the-ground-up.html">TensorFlow From The Ground Up</a></h3>
                        <p class="author-description">
                          
                        </p>
                    </div>
                </div>

            </div>

        </div>


    </footer>


</div>



    <footer class="index-footer">

        <a href="./" title="Slacy's Blog">Slacy's Blog</a>

    </footer>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-85612-4', 'auto');
      ga('send', 'pageview');

    </script>
</body>
</html>