<!DOCTYPE html>
<html lang="en">
<head>
        <title>NonlinearÂ Units</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css" />
        <link rel="stylesheet" href="./theme/css/main.css" />
</head>
<body>

    <div class="navigation pure-menu pure-menu-horizontal">
        <a href="./" class="pure-menu-heading  pure-menu-link">Slacy's Blog</a>
        <ul class="pure-menu-list">
            <li class="pure-menu-item"></li>

        </ul>
    </div>


<div class="page-container">
    <div class="entry-content">
        <div class="post-meta pure-g">
            <div class="pure-u">
                <a href="./category/tensorflow-from-the-ground-up.html"><img src="https://slacy.github.io/blog/images/tf_logo.png " class="post-avatar" alt="TensorFlow From The Ground Up"></a>
            </div>
<div class="pure-u-3-4 meta-data">
    <a href="./category/tensorflow-from-the-ground-up.html" class="category">TensorFlow From The Ground Up</a><br />

    <a class="author" href="./author/slacy.html">slacy</a>
    &mdash; <abbr title="2017-02-10T11:00:00-08:00">Fri 10 February 2017</abbr>
</div>        </div>
    </div>

    <div class="article-header-container">
        <div class="background-image-container">

            <div class="background-image-small">
                <div class="title-container">
                    <h1>Nonlinear&nbsp;Units</h1>
                </div>
            </div>
        </div>
    </div>

    <div class="entry-content">
        <p>This post part of my series <a href="./category/tensorflow-from-the-ground-up.html">TensorFlow From The Ground Up</a>.</p>
<p>In my previous post <a href="./learning-to-add.html">Learning to Add</a>, I showed how a Neural Network architecture can learn a simple linear function of two&nbsp;variables.  </p>
<p>In this post, we&#8217;ll explore how to take our functions from linear to nonlinear.  Additionally, we&#8217;ll work on going some <strong>regressions</strong> and see what happens when we try to learn nonlinear&nbsp;functions. </p>
<h2>Composing linear&nbsp;functions</h2>
<p>One of the key points of linear functions is that the composition of two linear functions is also a linear function.  The math behind this is fairly&nbsp;straightforward: </p>
<div class="math">$$\begin{array}{rl}
f(x) &amp; = wx+b \\
f(f(x)) &amp; = w_2(w_1x+b_1)+b_2 \\
&amp; = (w_2w_1)x+(w_2b_1+b_2) \\
\end{array}$$</div>
<p>As you can see, the composed form of <span class="math">\(f(f(x))\)</span> is also a linear function, just with <span class="math">\(w = w_2w_1\)</span> and <span class="math">\(b =&nbsp;w_2b_1+b_2\)</span></p>
<p>Or, to think of this differently:  Without any <strong>nonlinear elements</strong> in our neural network architecture, there&#8217;s no reason to have any more than one node in the middle layer, because even a giant collection of linear functions still result in a single linear&nbsp;transformation.  </p>
<p>An exception to this is functions of multiple variables, like <span class="math">\(f(x,y) = \{a,b\}\)</span>  We can work the math backwards, but let it suffice to say that for functions of <span class="math">\(N\)</span> inputs and <span class="math">\(M\)</span> outputs, we need no more than <span class="math">\(\max(N,M)\)</span> linear 
nodes in the middle&nbsp;layer. </p>
<h2>How do we introduce&nbsp;nonlinearity?</h2>
<p>All we need to do is apply some elementwise nonlinear function to all the values in the middle layer of our network.  It ends up making our computation graph look like&nbsp;this: </p>
<div class="math">$$\begin{array}{rl}
middle\ layer &amp; = input \times W_{mid} + B_{mid} \\
middle\ nonlinear &amp; = f(middle\ layer) \\ 
output &amp; = (midle\ nonlinear) \times W_{out} + B_{out}
\end{array}$$</div>
<p>It&#8217;s that easy, we just need to choose the right nonlinear function to insert there.  Thankfully, this has been heavily researched, and there are 3 very commonly used&nbsp;functions:</p>
<ul>
<li><strong>sigmoid</strong> : <code>tf.nn.sigmoid</code></li>
<li><strong>tanh</strong> : <code>tf.nn.tanh</code></li>
<li><strong>ReLu</strong>  : <code>tf.nn.relu</code></li>
</ul>
<p>The best way to get a grasp on these is to look at them visually, so here we&nbsp;go: </p>
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s1">&#39;svg&#39;</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span> 

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span> 
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="mi">0</span> 

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">relu</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ReLU&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="svg" src="./images/NonlinearUnits_files/NonlinearUnits_5_0.svg"></p>
<h2>Simple&nbsp;Example</h2>
<p>As an example of computation that requires nonlinear units, I&#8217;d like to propose that we implement a function like&nbsp;this: 
</p>
<div class="math">$$f(x) = \begin{cases}
    1.0, &amp; \text{if } \lfloor x \rfloor == 42 \\
    0,         &amp; \text{otherwise}
\end{cases}
$$</div>
<p>This function isn&#8217;t easily expressed through any combination of linear operators.  Additionally, the fact that the output should be either 1.0 or 0.0 after training suggests that we should use the <strong>sigmoid</strong> function for activation of the neuron(s) in the&nbsp;network. </p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span> 
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> 
    <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mf">42.0</span><span class="p">:</span> 
        <span class="k">return</span> <span class="mi">1</span> 
    <span class="k">return</span> <span class="mi">0</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>

<span class="n">num_hidden</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">i_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">expected_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">),</span> 
                <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">i_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">expected_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">),</span> 
                <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">mid</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i_w</span><span class="p">),</span> <span class="n">i_b</span><span class="p">))</span>

<span class="n">o_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
    <span class="n">expected_shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
    <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">((</span><span class="n">num_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">o_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
    <span class="n">expected_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
    <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="n">o_w</span><span class="p">),</span> <span class="n">o_b</span><span class="p">))</span>

<span class="c1"># Our error function is computed as &quot;Mean Squared Difference&quot; between the computed output</span>
<span class="c1"># and the expected value. </span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">output</span> <span class="o">-</span> <span class="n">o</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">mean_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="c1"># Learning rate and optimizer similar to our previous examples. </span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">RMSPropOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span> 
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">(),</span> 
              <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()])</span>

    <span class="k">print</span> <span class="s2">&quot;TRAIN&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">train_iterations</span> <span class="o">=</span> <span class="mi">30000</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">train_iterations</span><span class="p">):</span>
        <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:[],</span> <span class="n">o</span><span class="p">:[]}</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
<span class="c1">#            v = random.uniform(0, 100)</span>
<span class="c1">#            feed[i].append([v,])</span>
<span class="c1">#            feed[o].append([f(v),])</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
            <span class="n">feed</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">v</span><span class="p">,])</span>
            <span class="n">feed</span><span class="p">[</span><span class="n">o</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">),])</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mean_loss</span><span class="p">,</span> <span class="n">output</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="s2">&quot;step =&quot;</span><span class="p">,</span><span class="n">step</span><span class="p">,</span><span class="s2">&quot; loss=&quot;</span><span class="p">,</span> <span class="n">l</span>

    <span class="k">print</span> <span class="s2">&quot;VALIDATE&quot;</span>
    <span class="n">validate_iterations</span> <span class="o">=</span> <span class="mi">15</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">validate_iterations</span><span class="p">):</span>
        <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:[],</span> <span class="n">o</span><span class="p">:[]}</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">41</span><span class="p">,</span> <span class="mi">44</span><span class="p">)</span>
        <span class="n">feed</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">v</span><span class="p">,])</span>
        <span class="n">feed</span><span class="p">[</span><span class="n">o</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">),])</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mean_loss</span><span class="p">,</span> <span class="n">output</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
        <span class="k">print</span> <span class="s2">&quot;in = &quot;</span><span class="p">,</span> <span class="n">feed</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s2">&quot;output =&quot;</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="s2">&quot;expected = &quot;</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="s2">&quot; loss=&quot;</span><span class="p">,</span> <span class="n">l</span>
</pre></div>


<div class="highlight"><pre><span></span>TRAIN
step = 0  loss= 0.877057
step = 1000  loss= 0.104496
step = 2000  loss= 0.0742236
step = 3000  loss= 0.0900399
step = 4000  loss= 0.12191
step = 5000  loss= 0.0979266
step = 6000  loss= 0.0819742
step = 7000  loss= 0.113891
step = 8000  loss= 0.0578795
step = 9000  loss= 0.0500379
step = 10000  loss= 0.0979864
step = 11000  loss= 0.122138
step = 12000  loss= 0.0740604
step = 13000  loss= 0.0980238
step = 14000  loss= 0.113875
step = 15000  loss= 0.0980144
step = 16000  loss= 0.114098
step = 17000  loss= 0.0819586
step = 18000  loss= 0.0819596
step = 19000  loss= 0.122212
step = 20000  loss= 0.0979735
step = 21000  loss= 0.0579728
step = 22000  loss= 0.0739617
step = 23000  loss= 0.0499344
step = 24000  loss= 0.0740566
step = 25000  loss= 0.0335692
step = 26000  loss= 0.0900009
step = 27000  loss= 0.0900244
step = 28000  loss= 0.065831
step = 29000  loss= 0.0900088
VALIDATE
in =  [[42.418392103505745]] output = [[ 0.09433614]] expected =  1  loss= 0.820227
in =  [[41.27331682450373]] output = [[ 0.09447734]] expected =  0  loss= 0.00892597
in =  [[42.74300684100083]] output = [[ 0.0944618]] expected =  1  loss= 0.819999
in =  [[41.77018467542995]] output = [[ 0.09461799]] expected =  0  loss= 0.00895256
in =  [[41.71882226461412]] output = [[ 0.09460072]] expected =  0  loss= 0.0089493
in =  [[43.828811973181075]] output = [[ 0.09458257]] expected =  0  loss= 0.00894586
in =  [[43.316574487518395]] output = [[ 0.09456344]] expected =  0  loss= 0.00894224
in =  [[42.01840829969748]] output = [[ 0.09454328]] expected =  1  loss= 0.819852
in =  [[42.41435611237114]] output = [[ 0.09474455]] expected =  1  loss= 0.819487
in =  [[43.777608677423316]] output = [[ 0.09495493]] expected =  0  loss= 0.00901644
in =  [[42.27698122268134]] output = [[ 0.09493159]] expected =  1  loss= 0.819149
in =  [[41.167553882421814]] output = [[ 0.09516267]] expected =  0  loss= 0.00905593
in =  [[43.99910254663018]] output = [[ 0.09513699]] expected =  0  loss= 0.00905105
in =  [[43.16787136118454]] output = [[ 0.09510995]] expected =  0  loss= 0.0090459
in =  [[43.953262142856325]] output = [[ 0.09508146]] expected =  0  loss= 0.00904049
</pre></div>


<h2>You should play with this code a little&nbsp;bit.</h2>
<p>Here&#8217;s a collection of random ideas for how to play around with the code example above and gain some&nbsp;insights:</p>
<ul>
<li>Modify the &#8220;f()&#8221; function to try other linear combinations of x <span class="amp">&amp;</span> y.  Can it learn <span class="math">\(x-y\)</span>?  Can it learn <span class="math">\(0.5x + 0.75y - 0.33\)</span>? </li>
<li>Modify the size of the middle layer.  We use 2 middle layer nodes.  What if you use 200?  How does that impact learning&nbsp;rate?   </li>
<li>Modify the size of the middle layer, and have it try to learn something &#8220;Hard&#8221; like <span class="math">\(x\cdot y\)</span>. Did it work?  Do you have any thoughts about why or why&nbsp;not?</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div>

    <footer>
        <div class="tags">
            <a href="./tag/python.html">Python</a>
            <a href="./tag/tensorflow.html">TensorFlow</a>
            <a href="./tag/jupyter.html">Jupyter</a>
        </div>
        <div class="pure-g post-footer">
            <div class="pure-u-1 pure-u-md-1-2">
                <div class="pure-g poster-info">
                    <div class="pure-u">
                        <a href="./author/slacy.html"><img src="https://slacy.github.io/blog/images/ygg.png" alt=""></a>
                    </div>
                    <div class="pure-u-3-4">
                        <h3 class="author-name"><a href="./author/slacy.html">slacy</a></h3>
                        <p class="author-description">
                                              
                        </p>
                    </div>
                </div>
            </div>


            <div class="pure-u-1 pure-u-md-1-2">

                <div class="pure-g post-category-info">
                    <div class="pure-u">
                        <a href="./category/tensorflow-from-the-ground-up.html"><img src="https://slacy.github.io/blog/images/tf_logo.png" alt=""></a>
                    </div>
                    <div class="pure-u-3-4">
                        <h3 class="author-name"><a href="./category/tensorflow-from-the-ground-up.html">TensorFlow From The Ground Up</a></h3>
                        <p class="author-description">
                          
                        </p>
                    </div>
                </div>

            </div>

        </div>


    </footer>


</div>



    <footer class="index-footer">

        <a href="./" title="Slacy's Blog">Slacy's Blog</a>

    </footer>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-85612-4', 'auto');
      ga('send', 'pageview');

    </script>
</body>
</html>